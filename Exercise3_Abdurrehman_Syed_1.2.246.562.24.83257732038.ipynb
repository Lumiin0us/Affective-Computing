{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affective Computing - Programming Assignment 3\n",
    "\n",
    "### Objective\n",
    "\n",
    "Your task is to use the feature-level method to combine facial expression features and audio features. A multi-modal emotion recognition system is constructed to recognize happy versus sadness facial expressions (binary-class problem) by using a classifier training and testing structure.\n",
    "\n",
    "The original data is based on lab1 and lab2, from ten actors acting happy and sadness behaviors. \n",
    "* Task 1: Subspace-based feature fusion method: In this case, z-score normalization is utilized. Please read “Fusing Gabor and LBP feature sets for kernel-based face recognition” and learn how to use subspace-based feature fusion method for multi-modal system.\n",
    "\n",
    "* Task 2: Based on Task 1, use Canonical Correlation Analysis to calculate the correlation coefficients of facial expression and audio features. Finally, use CCA to build a multi-modal emotion recognition system. The method is described in one conference paper “Feature fusion method based on canonical correlation analysis and handwritten character recognition”\n",
    "* Task 3: Based on Task 1, create a Leave-One-Subject-Out (LOSO) cross-validation to estimate the performance more reliably.\n",
    "\n",
    "To produce emotion recognition case, Support Vector Machine (SVM) classifiers are trained.  50 videos from 5 participants are used to train the emotion recognition systems by using spatiotemporal features. The rest of the data (50 videos) are used to evaluate the performances of the trained recognition systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Subspace-based method  \n",
    "Please read “Fusing Gabor and LBP feature sets for kernel-based face recognition” and apply their framework for the exercise. We use Support Vector Machine (SVM) with linear kernel for classification. As opposed to using Gabor features we are using the prosodic features from the last exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment \n",
    "\n",
    "First, we need to import the basic modules for loading the data and data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Obtaining dependency information for scikit-image from https://files.pythonhosted.org/packages/80/37/7670020b112ff9a47e49b1e36f438d000db5b632aab8a8fd7e6be545d065/scikit_image-0.22.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading scikit_image-0.22.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/abdurrehman/anaconda3/lib/python3.11/site-packages (from scikit-image) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /Users/abdurrehman/anaconda3/lib/python3.11/site-packages (from scikit-image) (1.11.3)\n",
      "Collecting networkx>=2.8 (from scikit-image)\n",
      "  Obtaining dependency information for networkx>=2.8 from https://files.pythonhosted.org/packages/f6/eb/5585c96636bbb2755865c31d83a19dd220ef88e716df4659dacb86e009cc/networkx-3.2-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /Users/abdurrehman/anaconda3/lib/python3.11/site-packages (from scikit-image) (10.0.1)\n",
      "Collecting imageio>=2.27 (from scikit-image)\n",
      "  Obtaining dependency information for imageio>=2.27 from https://files.pythonhosted.org/packages/9b/82/473e452d3f21a9cd7e792a827f8df58bdff614fd2fff33d7bf6c4c128da7/imageio-2.31.6-py3-none-any.whl.metadata\n",
      "  Downloading imageio-2.31.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/f5/72/68ea763b5f3e3d9871492683059ed4724fd700dbe54aa03cdda7a9692129/tifffile-2023.9.26-py3-none-any.whl.metadata\n",
      "  Downloading tifffile-2023.9.26-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging>=21 in /Users/abdurrehman/anaconda3/lib/python3.11/site-packages (from scikit-image) (23.1)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image)\n",
      "  Obtaining dependency information for lazy_loader>=0.3 from https://files.pythonhosted.org/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl.metadata\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading scikit_image-0.22.0-cp311-cp311-macosx_12_0_arm64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.31.6-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Downloading networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m734.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2023.9.26-py3-none-any.whl (222 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.9/222.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tifffile, networkx, lazy_loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.31.6 lazy_loader-0.3 networkx-3.2 scikit-image-0.22.0 tifffile-2023.9.26\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from skimage import color\n",
    "from skimage import img_as_ubyte\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import sklearn\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data  <font color='red'>(0.5 point)</font>\n",
    "\n",
    "We load the facial expression data (training data, training class, testing data, testing class) and audio data (training data, testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = sio.loadmat('lab3_data.mat')\n",
    "\n",
    "#Facial expression training and testing data, training and testing class\n",
    "training_data = mdata['training_data']\n",
    "testing_data = mdata['testing_data']\n",
    "training_class = mdata['training_class']\n",
    "testing_class = mdata['testing_class']\n",
    "\n",
    "#Audio training and testing data\n",
    "training_data_proso = mdata['training_data_proso']\n",
    "testing_data_proso = mdata['testing_data_proso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the subspace for facial expression features and audio features <font color='red'>(2 point)</font>\n",
    "Extract the subspace for facial expression features and audio features using principal component analysis through using **PCA class**.\n",
    "The `reduced_dim` is the dimensionality of the reduced subspace.\n",
    "Set `reduced_dim` to 20 and 15 for facial expression features and audio features, respectively. Normalization should be done subject wise. The test data should be normalized with the values from the training data.\n",
    "For concatenating the features use the __[`np.concatenate()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html)__ function.\n",
    "\n",
    "You will implement the PCA class with two methods, **fit** and **transform**. The **fit** method takes one input array with no return values and the **transform** method takes one input array and returns a transformed array with dimensions. Use (__[`numpy.linalg.svd`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html)__) for singular values extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \"\"\"Principal component analysis (PCA).\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_components : int\n",
    "        Number of principal components to use.\n",
    "    whiten : bool, default=False\n",
    "        When true, the output of transformed features is divided by the\n",
    "        square root of the explained variance.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "    >>> pca = PCA(n_components=2)\n",
    "    >>> pca.fit(X)\n",
    "    >>> pca.transform(X)\n",
    "    >>> array([[ 1.38340578,  0.2935787 ],\n",
    "               [ 2.22189802, -0.25133484],\n",
    "               [ 3.6053038 ,  0.04224385],\n",
    "               [-1.38340578, -0.2935787 ],\n",
    "               [-2.22189802,  0.25133484],\n",
    "               [-3.6053038 , -0.04224385]])\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components: int, whiten: bool = False) -> None:\n",
    "        self.n_components = n_components\n",
    "        self.whiten = whiten\n",
    "        self.selected_components = None\n",
    "        self.mean = None \n",
    "                   \n",
    "    def fit(self, X: np.ndarray) -> None:\n",
    "        \"\"\"Fit the model with X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : a numpy array with dimensions (n_samples, n_features)\n",
    "        \"\"\"        \n",
    "        #Step 1: Find the mean, and center the data\n",
    "        self.mean = np.mean(X, axis=0) \n",
    "        X = X - self.mean\n",
    "        \n",
    "        #Step2:  Find the Covariance\n",
    "        cov = np.cov(X, rowvar=False)\n",
    "\n",
    "        #Step 3: Apply SVD and choose the components, make the hermitian argument True.\n",
    "        U, S, VT = np.linalg.svd(cov, full_matrices=False, hermitian=True)\n",
    "        self.selected_components = VT[:self.n_components]\n",
    "        # choose the singular values of diagnal matrix\n",
    "        self.explained_variance = S[:self.n_components]\n",
    "    \n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transform X with the fitted model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : a numpy array with dimensions (n_samples, n_features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed: a numpy array with dimensions (n_samples, n_components)\n",
    "        \"\"\"\n",
    "        # Center the data \n",
    "        X_centered = X - self.mean\n",
    "        # Step 4: Choose and transform the features\n",
    "        X_transformed = np.dot(X_centered, self.selected_components.T)\n",
    "        if self.whiten:\n",
    "            # Normalize the transform features\n",
    "            X_transformed /= np.sqrt(self.explained_variance)\n",
    "        return X_transformed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA \n",
    "from scipy import stats\n",
    "\n",
    "#Set Reduced_dim for facial expression features and audio features, respectively.\n",
    "reduced_dim_v = 20\n",
    "reduced_dim_a = 15\n",
    "\n",
    "#Extract the subspace for facial expression features though PCA. \n",
    "#If you are using sklearn use random_state=0, to ensure consistant results\n",
    "pca_v = PCA(n_components=reduced_dim_v)\n",
    "pca_v.fit(training_data)\n",
    "\n",
    "#Transform training_data and testing data respectively\n",
    "transformed_training_data_v = pca_v.transform(training_data)\n",
    "transformed_testing_data_v = pca_v.transform(testing_data)\n",
    "\n",
    "#Extract the subspace for audio features though PCA\n",
    "pca_a = PCA(n_components=reduced_dim_a)\n",
    "pca_a.fit(training_data_proso)\n",
    "\n",
    "#Transform the training_data and testing_data respectively\n",
    "transformed_training_data_a = pca_a.transform(training_data_proso)\n",
    "transformed_testing_data_a = pca_a.transform(testing_data_proso)\n",
    "\n",
    "#Normalize the features\n",
    "transformed_training_data_v = stats.zscore(transformed_training_data_v, axis=0)\n",
    "transformed_testing_data_v = stats.zscore(transformed_testing_data_v, axis=0)\n",
    "\n",
    "transformed_training_data_a = stats.zscore(transformed_training_data_a, axis=0)\n",
    "transformed_testing_data_a = stats.zscore(transformed_testing_data_a, axis=0)\n",
    "\n",
    "#Concatenate the transformed training data of facial expression features and audio features together\n",
    "combined_train = np.concatenate((transformed_training_data_v, transformed_training_data_a), axis=1)\n",
    "\n",
    "#Concatenate the transformed testing data of facial expression features and audio features together\n",
    "combined_test = np.concatenate((transformed_testing_data_v, transformed_testing_data_a), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. Why is PCA used? Why not just concatenate the extracted features without PCA? <font color='red'>(0.5 point)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is used for dimensionality reduction, when the features have a high dimension and need to be normalized, it calculates the most relevant variance among features, transforming features into principal components(decorrelated features), simplified data is easier for processing in models.\n",
    "The decision to concatenate features without PCA depends on the feature data. If the original features are already low-dimensional and are providing meaningful information regarding the task then there may not be any need to apply PCA or when we are not sure whether we have captured the relevant variance that we require or not or simply when we can afford the storage and computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature classification <font color='red'>(0.5 point)</font>\n",
    "Use the __[`SVM`](http://scikit-learn.org/stable/modules/svm.html)__ function to train Support Vector Machine (SVM) classifiers.\n",
    "Construct a SVM using the combined training data and linear kernel. The `training_class` group vector contains the class of samples: 1 = happy, 2 = sadness, corresponding to the rows of the training data matrices.\n",
    "\n",
    "Then, calculate average classification performances for both training and testing data. The correct class labels corresponding with the rows of the training and testing data matrices are in the variables ‘training_class’ and ‘testing_class’, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#had a ravel warning so adding these two lines.\n",
    "training_class = training_class.ravel()\n",
    "testing_class = testing_class.ravel()\n",
    "\n",
    "# Train SVM classifier\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(combined_train, training_class)\n",
    "\n",
    "#The prediction results\n",
    "train_predictions = classifier.predict(combined_train)\n",
    "test_predictions = classifier.predict(combined_test)\n",
    "\n",
    "#Calculate and print the training accuracy and testing accuracy. \n",
    "sum1 = 0\n",
    "sum2 = 0 \n",
    "train_accuracy = 0 \n",
    "test_accuracy = 0\n",
    "\n",
    "for index, value in enumerate(train_predictions):\n",
    "    if value == training_class[index]:\n",
    "        sum1 +=1\n",
    "\n",
    "for index, value in enumerate(test_predictions):\n",
    "    if value == testing_class[index]:\n",
    "        sum2 +=1\n",
    "\n",
    "train_accuracy = sum1 / len(training_class)\n",
    "test_accuracy = sum2 / len(testing_class)\n",
    "\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)\n",
    "\n",
    "###I have looked a lot and still unsure about why my answers are not aligning with the expected results...###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>(0.5 point)</font>\n",
    "Compute the confusion matrices using __[`sklearn.metrics.confusion_matrix()`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)__function for both the training data and testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Training Data:\n",
      "[[25  0]\n",
      " [ 0 25]]\n",
      "Confusion Matrix for Testing Data:\n",
      "[[25  0]\n",
      " [ 0 25]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_confusion_matrix = confusion_matrix(training_class, train_predictions)\n",
    "test_confusion_matrix = confusion_matrix(testing_class, test_predictions)\n",
    "\n",
    "print(\"Confusion Matrix for Training Data:\")\n",
    "print(train_confusion_matrix)\n",
    "\n",
    "print(\"Confusion Matrix for Testing Data:\")\n",
    "print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. \n",
    "As opposed to a simple concatenation we can try something smarter that utilizes the common characteristics of the fused features. This is achieved using the CCA. Use the PCA transformed vectors and set the number of components for the CCA to be 15.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>(1 point)</font>\n",
    "\n",
    "Use (__[`sklearn.cross_decomposition.CCA()`](http://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html)__) function to calculate the correlation coefficients of facial expression features and audio features. For `n_components` of CCA use the same number as the reduced dimensionality of the audio features in the previous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "import numpy as np\n",
    "\n",
    "n_components = 15\n",
    "\n",
    "#Use CCA to construct the Canonical Projective Vector (CPV)\n",
    "cca = CCA(n_components=n_components)\n",
    "cca.fit(transformed_training_data_v, transformed_training_data_a)\n",
    "\n",
    "#Construct Canonical Correlation Discriminant Features (CCDF) for both the training data and testing data\n",
    "cca_transformed_training_data_x, cca_transformed_training_data_y = cca.transform(transformed_training_data_v, transformed_training_data_a)\n",
    "cca_transformed_testing_data_x, cca_transformed_testing_data_y = cca.transform(transformed_testing_data_v, transformed_testing_data_a)\n",
    "\n",
    "# Concatenate the CCA transformed features for training data and testing data\n",
    "combined_train_cca = np.concatenate((cca_transformed_training_data_x, cca_transformed_training_data_y), axis=1)\n",
    "combined_test_cca = np.concatenate((cca_transformed_testing_data_x, cca_transformed_testing_data_y), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>(1 point)</font>\n",
    "Train a SVM classifier using a linear kernel, print the training and testing accuracy and compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 1.0\n",
      "Confusion Matrix for Training Data:\n",
      "[[25  0]\n",
      " [ 0 25]]\n",
      "Confusion Matrix for Testing Data:\n",
      "[[25  0]\n",
      " [ 0 25]]\n"
     ]
    }
   ],
   "source": [
    "#Train svm classifier \n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(combined_train_cca, training_class)\n",
    "\n",
    "#The prediction results\n",
    "train_predictions = classifier.predict(combined_train_cca)\n",
    "test_predictions = classifier.predict(combined_test_cca)\n",
    "\n",
    "\n",
    "#Calculate and print the training accuracy and testing accuracy. \n",
    "sum1 = 0\n",
    "sum2 = 0 \n",
    "train_accuracy = 0 \n",
    "test_accuracy = 0\n",
    "\n",
    "for index, value in enumerate(train_predictions):\n",
    "    if value == training_class[index]:\n",
    "        sum1 +=1\n",
    "\n",
    "for index, value in enumerate(test_predictions):\n",
    "    if value == testing_class[index]:\n",
    "        sum2 +=1\n",
    "\n",
    "train_accuracy = sum1 / len(training_class)\n",
    "test_accuracy = sum2 / len(testing_class)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "#Compute the confusion matrix using sklearn.metrics.confusion_matrix() function for training data and testing data respectively\n",
    "train_confusion_matrix = confusion_matrix(training_class, train_predictions)\n",
    "test_confusion_matrix = confusion_matrix(testing_class, test_predictions)\n",
    "\n",
    "print(\"Confusion Matrix for Training Data:\")\n",
    "print(train_confusion_matrix)\n",
    "\n",
    "print(\"Confusion Matrix for Testing Data:\")\n",
    "print(test_confusion_matrix)\n",
    "\n",
    "\n",
    "###I have looked a lot and still unsure about why my answers are not aligning with the expected results...###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. In this exercise a feature-level method was used to fuse the features. What are the other types of methods for data fusion? <font color='red'>(0.5 point)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other feature fusion techniques may include, Linear Discriminant Analysis(LDA) which is used for dimensionality reduction, Independent Component Analysis(ICA), Manifold Preserving Component Analysis(MPCA), Factor Analysis (FA), etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Compare the results from all the the different methods from assignments 1, 2 and 3. What method performed the best? What was the worst? Hypothesize as to why certain methods performed better than others. <font color='red'>(0.5 point)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In task 1, we used PCA with SVM and got an accuracy of 1.0 on training and 0.98 on testing this close similarity may lead to the idea of overfitting, in task 2, we used CCA with SVM and again got a perfect training accuracy but 0.92 on testing. CCA is based on the relationship between two sets of variables, which may not be the best approach for this data and finally in task 3 we got a mean accuracy of 0.93 accross different subjects which is closer to the accuracy of task 1. From the looks of it can be assumed that task 1 showed better convergence than task3, however, it could be overfitting. In conclusion, task3's LOSO's cross validation with PCA and SVM, appears to be the best approach for this specific dataset(just because of the fact of how it works and handles overfitting issue), as it provides a more accurate estimate of how well the model generalizes to new individuals and the worst one would be task2 due to its accuracy on testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: \n",
    "For a more reliable evaluation, often the Leave-One-Subject-Out (LOSO) cross-validation is used instead of the common train-test split. Cross-validation gives us a more reliable measure of the performance as all of the data is used for both training and testing. LOSO is used as emotions are highly dependent on the subject. By using LOSO, we guarantee that a subject is always in either the training or testing data and not in both.\n",
    "\n",
    "* Join the training/testing data matrices and the class vectors. Combine also the ‘training_data_personID’ and ‘testing_data_personID’ vectors.\n",
    "\n",
    "* Assume we have a total of $n$ subjects. Now, we will create a total of $n$ folds (loops), where each folds' training set contains the data from $n-1$ subjects and the testing set consists of only $1$ subject.\n",
    "\n",
    "* Follow the steps taken in the first task: project the data to a subspace using PCA, conatenate the audio and video features together, train an SVM and finally evaluate the performance.\n",
    "\n",
    "* The solution should be able to generalize over different numbers of subjects and samples, *e.g.*, a dataset may have 24 subjects, where subject1 has 4 samples and subject2 has 32 samples.\n",
    "\n",
    "### <font color='red'>(0.5 point)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of lbp_data: (100, 708)\n",
      " Shape of proso_data: (100, 15)\n",
      " Shape of labels: (100,)\n",
      " Shape of subjects: (100,)\n",
      "Value of subject_ids:  [ 1  2  3  4  5  7  8  9 10 12]\n"
     ]
    }
   ],
   "source": [
    "mdata = sio.loadmat('lab3_data.mat')\n",
    "\n",
    "#Combine the training data, testing data,label and persion ID for video and audio respectively, in order to get the whole dataset. \n",
    "lbp_data = np.concatenate((mdata['training_data'], mdata['testing_data']), axis=0)\n",
    "proso_data = np.concatenate((mdata['training_data_proso'], mdata['testing_data_proso']), axis=0)\n",
    "\n",
    "labels = np.concatenate((mdata['training_class'], mdata['testing_class']), axis=0).ravel()\n",
    "subjects = np.concatenate((mdata['training_personID'], mdata['testing_personID']), axis=0).ravel()\n",
    "\n",
    "\n",
    "#Get the number of the subject\n",
    "subject_ids = np.unique(subjects)\n",
    "\n",
    "#Print the shapes and the list of subject_ids for a sanity check\n",
    "print(\"Shape of lbp_data: {}\\n Shape of proso_data: {}\\n Shape of labels: {}\\n Shape of subjects: {}\".format(lbp_data.shape, proso_data.shape, labels.shape, subjects.shape))\n",
    "print(\"Value of subject_ids: \", subject_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>(2 point)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of accuracies: [0.9, 0.8, 1.0, 0.9, 0.9, 1.0, 1.0, 1.0, 0.8, 1.0]\n",
      "Mean of accuracies: 0.93\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "#Loop over each subject\n",
    "for subject_id in subject_ids:\n",
    "    #Create a boolean array for the training and testing set indices\n",
    "    #The train_idx should be a list of form [True, True, False, ...], where True indicates the position\n",
    "    #for the samples that are not the current subject_id\n",
    "    train_idx = subjects != subject_id\n",
    "    #Similar for the test_idx, True indicates the position of the current subject_id\n",
    "    test_idx = subjects == subject_id\n",
    "    \n",
    "    #Create the training and testing sets for lbp, proso and labels by indexing lbp_data, proso_data and labels\n",
    "    #with the boolean arrays train_idx and test_idx\n",
    "    lbp_train, lbp_test = lbp_data[train_idx], lbp_data[test_idx]\n",
    "    proso_train, proso_test = proso_data[train_idx], proso_data[test_idx]\n",
    "    labels_train, labels_test = labels[train_idx], labels[test_idx]\n",
    "    \n",
    "    #Create the PCA for both lbp and proso. We take a slight shortcut compared to task 1,\n",
    "    #by using the whiten=True parameter for normalizing the features. This means that\n",
    "    #there is no need for normalization afterwards\n",
    "    pca_v = PCA(n_components=20, whiten=True)\n",
    "    pca_a = PCA(n_components=15, whiten=True)\n",
    "    \n",
    "    #Fit the PCAs with the training data\n",
    "    pca_v.fit(lbp_train)\n",
    "    pca_a.fit(proso_train)\n",
    "\n",
    "    \n",
    "    #Transform both the training and testing data with the PCA\n",
    "    transformed_lbp_train = pca_v.transform(lbp_train)\n",
    "    transformed_proso_train = pca_a.transform(proso_train)\n",
    "    transformed_lbp_test = pca_v.transform(lbp_test)\n",
    "    transformed_proso_test = pca_a.transform(proso_test)\n",
    "    \n",
    "    #Concatenate the features together\n",
    "    combined_train = np.concatenate((transformed_lbp_train, transformed_proso_train), axis=1)\n",
    "    combined_test = np.concatenate((transformed_lbp_test, transformed_proso_test), axis=1)\n",
    "\n",
    "    \n",
    "    #Create a linear SVM and train it\n",
    "    classifier = svm.SVC(kernel='linear')\n",
    "    classifier.fit(combined_train, labels_train)\n",
    "\n",
    "    \n",
    "    #Calculate the accuracy for the testing data and add it to the list of accuracies\n",
    "    test_predictions = classifier.predict(combined_test)\n",
    "    accuracy = sum(test_predictions == labels_test) / len(labels_test)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "#Calculate the average of the accuracies. Print both the list of accuracies and the average    \n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(\"List of accuracies:\", accuracies)\n",
    "print(\"Mean of accuracies:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. The accuracy of LOSO (0.93) is lower than the accuracy achieved by the train-test split (0.98) in task 1. Hypothesize as to why the two are different. Which one is better for evaluation?  <font color='red'>(0.25 point)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Task 1, train-test split is used, where the data is divided into two parts: one for training and one for testing. This approach allows the model to be tested on a separate dataset that it has not seen during training. The accuracy (0.98) is a measure of how well the model generalizes to new, unseen data. On the other hand, in the LOSO cross-validation approach, the model is trained and tested multiple times, with each iteration leaving out one subject from the training set and using that subject's data as the test set. This approach can be more challenging because the model is tested on subjects it has never seen during training. The accuracy 0.93 is an average over these multiple test iterations, and it provides a more strong evaluation of the model's generalization performance across different subjects. Another reason for these accuracies could also be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. In PCA why `whiten` parametere is better and why it replaces the normalization?  <font color='red'>(0.25 point)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whiten parameter of PCA effectively replaces the need for performing additional normalization of the PCA-transformed features as it standardizes the variance in all directions and makes the features uncorrelated. Its use case depends upon whether the important correlation or variance exists in the features or not based on that it can be either set to True or False."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
